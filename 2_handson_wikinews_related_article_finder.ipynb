{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "\n",
    "Download the pre-cooked `textacy.Corpus` from Dropbox: [Download here](https://www.dropbox.com/s/wlbyvxdfnx748bg/textacy_corpus.bin.gz?dl=1) (118MB) to `./data/enwikinews/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "from datetime import datetime\n",
    "\n",
    "dt_format = \"%Y-%m-%dT%H:%M:%SZ\"  # for parsing Wikinews' timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = textacy.Corpus.load(\"en_core_web_md\", \"./data/enwikinews/textacy_corpus.bin.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment\n",
    "\n",
    "This hands on session aims to improve Wikinews' existing \"Related articles\"-widget, by incorporating a two-step pre-retrieval and re-rank methodology. More specifically, we expect you to create:\n",
    "\n",
    "### 1. Candidate retrieval\n",
    "\n",
    "One method that takes as input a `textacy.Corpus` document, and as output a (ranked) list of candidate 'related articles'. A textacy-based reimplementation of a simple `candidate_retriever` could be:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidate_retriever(doc, corpus, limit=10):\n",
    "    \"\"\"\n",
    "    Retrieve candidate articles \"related\" to doc in corpus\n",
    "    \"related\" here means documents that have one or more categories in common.\n",
    "    \"\"\"\n",
    "    \n",
    "    doc_categories = doc._.meta[\"categories\"]\n",
    "    \n",
    "    # Match if the candidate doc (`c`) has any category overlapping with input doc (`doc`)\n",
    "    match_func = lambda c: any([cat in doc_categories \n",
    "                                for cat in c._.meta.get(\"categories\")])\n",
    "    \n",
    "    # match_func = lambda c: \"Obituaries\" in c._.meta['categories']  # Or: match category \"Obituaries\"\n",
    "    \n",
    "    candidates = corpus.get(lambda x: \"Obituaries\" oin x._.meta['categories', limit=limit)\n",
    "    \n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Re-ranking\n",
    "\n",
    "The second step consists of re-ranking the set of candidate articles using some criterium. In the case of Wikinews, it is ranked by recency (newest first), i.e.;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_ranker(candidates):\n",
    "    \"\"\" Sorts candidates by date created\"\"\"\n",
    "    \n",
    "    ranked_candidates = sorted(list(candidates), key=lambda x: datetime.strptime(x._.meta['dt_created'], \n",
    "                                                                                 dt_format), reverse = True)\n",
    "    \n",
    "    return ranked_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = candidate_retriever(corpus[16127], corpus)\n",
    "ranked_candidates = re_ranker(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in ranked_candidates:\n",
    "    print(c._.meta['dt_created'], c._.meta['title'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
